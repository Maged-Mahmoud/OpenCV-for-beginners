{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OpenCV Lib\n",
    "import cv2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Images , Videos, Cameras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image\n",
    "img = cv2.imread('men.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the image\n",
    "cv2.imshow('Image_output',img)\n",
    "'''\n",
    "the waitkey is important to keep showing the image for a specific period of time\n",
    "(0 for keep showing always , 1000 for one second and etc.....)\n",
    "'''\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing a video or live camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,540) # setting width \n",
    "cap.set(4,320) # setting height\n",
    "cap.set(10,50) # setting brightness\n",
    "\n",
    "while True: \n",
    "    '''this loop is for showing the video or camera '''\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow('Camera' , img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # this quits the video window if we press on \"q\"\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic images Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('men.jpg')\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# convert colored image to gray \n",
    "cv2.imshow('Gray image',img_gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('men.jpg')\n",
    "img_blur = cv2.GaussianBlur(img,(5,5),1)# blurring the image\n",
    "cv2.imshow('Blur Image',img_blur)\n",
    "cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('men.jpg')\n",
    "img_canny = cv2.Canny(img,100,100)#  showing the image edges\n",
    "cv2.imshow('Canny Image',img_canny)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "img_dilation = cv2.dilate(img_canny,kernel,iterations = 1)# increasing the painting of the edges \n",
    "cv2.imshow('dilate Image',img_dilation)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_eroded = cv2.erode(img_dilation,kernel,iterations = 1)# reverse process of dilation / erode some areas from edges\n",
    "cv2.imshow('eroded Image',img_eroded)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing and Cropping Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 284, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape) #(height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_resized = cv2.resize(img,(200,100))# resize image (width,height)\n",
    "cv2.imshow('resized Image',img_resized)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cropped = img[:,:150]# Cropping images[height,width]\n",
    "cv2.imshow('cropped Image',img_cropped)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes and Texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw a line on the image\n",
    "img = cv2.imread('men.jpg')\n",
    "img_copy = img.copy()\n",
    "cv2.line(img_copy,(0,0),(img.shape[1],img.shape[0]),(0,0,0),3)\n",
    "cv2.imshow('line',img_copy)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a rectangle inside the image\n",
    "cv2.rectangle(img_copy,(0,0),(img.shape[1],img.shape[0]),(0,0,255),3)\n",
    "cv2.imshow('rectangle',img_copy)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a circle inside the image\n",
    "cv2.circle(img_copy,(90,140),30,(255,0,0),5)\n",
    "cv2.imshow('circle',img_copy)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert a text inside the image\n",
    "cv2.putText(img_copy,'Hello',(140,90),cv2.FONT_HERSHEY_DUPLEX,2,(255,255,255),2)\n",
    "cv2.imshow('text inside image',img_copy)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp Perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 259, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('uno.jpg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width,height = 87,142\n",
    "pts1 = np.float32([[30,50],[117,21],[75,192],[167,160]])\n",
    "pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "image_output = cv2.warpPerspective(img,matrix,(width,height))\n",
    "image_output = cv2.resize(image_output,(img.shape[1],img.shape[0]))\n",
    "cv2.imshow('Warp image',image_output)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function is designed to to stack multiple images in the same window with certain scale'''\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_stack = stackImages(1.5,([img,image_output]))\n",
    "cv2.imshow('stacked images',img_stack)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Detect the color of the certain part in the image depending on the mask'''\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('TrackBars')\n",
    "cv2.resizeWindow('TrackBars',640,480)\n",
    "cv2.createTrackbar('sat min', 'TrackBars',0,100,empty)\n",
    "cv2.createTrackbar('sat max', 'TrackBars',100,200,empty)\n",
    "cv2.createTrackbar('sharp min', 'TrackBars',0,100,empty)\n",
    "cv2.createTrackbar('sharp max', 'TrackBars',100,200,empty)\n",
    "cv2.createTrackbar('h min', 'TrackBars',0,100,empty)\n",
    "cv2.createTrackbar('h max', 'TrackBars',100,200,empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread('men.jpg')\n",
    "    s_min = cv2.getTrackbarPos('sat min','TrackBars')\n",
    "    s_max = cv2.getTrackbarPos('sat max','TrackBars')\n",
    "    sh_min = cv2.getTrackbarPos('sharp min','TrackBars')\n",
    "    sh_max = cv2.getTrackbarPos('sharp max','TrackBars')\n",
    "    h_min = cv2.getTrackbarPos('h min','TrackBars')\n",
    "    h_max = cv2.getTrackbarPos('h max','TrackBars')\n",
    "    \n",
    "    lower = np.array([s_min,sh_min,h_min])\n",
    "    upper = np.array([s_max,sh_max,h_max])\n",
    "    \n",
    "    mask = cv2.inRange(img,lower,upper)\n",
    "    img_result = cv2.bitwise_and(img,img,mask=mask)\n",
    "    cv2.imshow('result',img_result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # this quits the video window if we press on \"q\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour and Shape Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This function detects the shapes in the image and outline them as well as iserting text inside each shape'''\n",
    "def getcontours(img):\n",
    "    _, contours, _ = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cont in contours:\n",
    "        area = cv2.contourArea(cont)                               # area of the detected shape\n",
    "        if area>200:\n",
    "            cv2.drawContours(img_contours,cont,-1,(0,0,0),3)       # outline the shape\n",
    "            peri = cv2.arcLength(cont,True)                        # the perimeter of the shape\n",
    "            approx = cv2.approxPolyDP(cont,0.02*peri,True)         # corners (points) of the shape\n",
    "            objcor = len(approx)\n",
    "            x,y,w,h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(img_contours,(x,y),(x+w,y+h),(255,255,0),2)# draw a bounding box \n",
    "            if objcor == 3: objectshape = 'Triangle'\n",
    "            elif objcor==4:\n",
    "                aspratio = w/float(h)\n",
    "                if 0.95<aspratio<1.05:\n",
    "                    objectshape = 'Square'\n",
    "                else:\n",
    "                     bjectshape='Rectangle'\n",
    "            elif objcor>4: objectshape='Circle'\n",
    "            else:\n",
    "                objectshape= 'None'\n",
    "            \n",
    "            cv2.putText(img_contours,objectshape,(x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,255,0),2)\n",
    "    return\n",
    "\n",
    "img = cv2.imread('shapes.png')\n",
    "img_contours = img.copy()\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\n",
    "imgCanny = cv2.Canny(imgBlur,50,50)\n",
    "\n",
    "getcontours(imgCanny)\n",
    "cv2.imshow('result',img_contours)\n",
    "cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' we will use builtin cascaded files '''\n",
    "\n",
    "while True: \n",
    "    '''this loop is for showing the video or camera '''\n",
    "    facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,540) # setting width \n",
    "    cap.set(4,320) # setting height\n",
    "    cap.set(10,100) # setting brightness\n",
    "\n",
    "    success, img = cap.read()\n",
    "    faces = facecascade.detectMultiScale(img,1.1,4)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "    cv2.imshow('face detector',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # this quits the video window if we press on \"q\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
